{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Workspace\n",
    "\n",
    "workspace_name = \"mlw-example\"\n",
    "\n",
    "ws_basic = Workspace(\n",
    "    name = workspace_name,  #your workspace name\n",
    "    location = \"eastus\",    #inwhich server location is used\n",
    "    display_name = \"Basic workspace-example\"    #name of the workspace displayed\n",
    "    description = \"This example shows how to create a basic workspace\"  #description\n",
    ")\n",
    "\n",
    "ml_client.workspace.begin_create(ws_basic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any file generated (and captured) from an experiment's run or job is an artifact. It may represent a model serialized as a Pickle file, the weights of a PyTorch or TensorFlow model, or even a text file containing the coefficients of a linear regression. Other artifacts can have nothing to do with the model itself, but they can contain configuration to run the model, pre-processing information, sample data, etc. As you can see, an artifact can come in any format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Azure Machine Learning, logging models has the following advantages:\n",
    "\n",
    "* You can deploy them on real-time or batch endpoints without providing an scoring script nor an environment.\n",
    "* When deployed, Model's deployments have a Swagger generated automatically and the Test feature can be used in Azure Machine Learning studio.\n",
    "* Models can be used as pipelines inputs directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlfow\n",
    "import pickle\n",
    "\n",
    "filename = 'model.pkl'\n",
    "with open(filename, 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "mlflow.log_artifact(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to log model\n",
    "import mlflow\n",
    "mlflow.sklearn.log_model(sklearn_estimator, \"classifier\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
